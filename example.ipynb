{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Time Voice Cloning\n",
    "\n",
    "With this example, we will submit a sample batch processing job to SageMaker. Make sure your run ./scripts/install.sh first. If you have the AWS CLI installed, you should be able to run this notebook locally. The transform() task however, will still run in the cloud on a GPU instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = ''              # <-- Your bucket name goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker as sage\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sage.Session()\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "trans = sage.transformer.Transformer('voice-cloning-recall', 1, 'ml.p2.xlarge')\n",
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Job\n",
    "\n",
    "Here, we setup our batch processing job to clone two sample voices. Let's have Darth Vader and Morgan Freeman read some novel passages. Of course, you could do this with different utterance files or text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hp_text = [\"Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much.\",\n",
    "           \"They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense.\",\n",
    "           \"Mr. Dursley was the director of a firm called Grunnings, which made drills.\",\n",
    "           \"He was a big, beefy man with hardly any neck, although he did have a very large mustache.\",\n",
    "           \"Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors.\",\n",
    "           \"The Dursleys had a small son called Dudley and in their opinion there was no finer boy anywhere.\"\n",
    "          ]\n",
    "\n",
    "two_cities_text = [\"It was the best of times, it was the worst of times\",\n",
    "                   \"it was the age of wisdom, it was the age of foolishness\",\n",
    "                   \"it was the epoch of belief, it was the epoch of incredulity\"\n",
    "                  ]\n",
    "\n",
    "job_json = {}\n",
    "job_json['request_id'] = 'test'\n",
    "job_json['request_type'] = 'batch_processing'\n",
    "\n",
    "job1 = {}\n",
    "job1['job_id'] = 'freeman_hp'\n",
    "job1['bucket'] = bucket_name\n",
    "job1['utterance_file'] = 'ssre-normal.wav'\n",
    "job1['sentences'] = hp_text\n",
    "\n",
    "job2 = {}\n",
    "job2['job_id'] = 'freeman_two_cities'\n",
    "job2['bucket'] = bucket_name\n",
    "job2['utterance_file'] = 'ssre-normal.wav'\n",
    "job2['sentences'] = two_cities_text\n",
    "\n",
    "job3 = {}\n",
    "job3['job_id'] = 'vader_hp'\n",
    "job3['bucket'] = bucket_name\n",
    "job3['utterance_file'] = 'darth.mp3'\n",
    "job3['sentences'] = hp_text\n",
    "\n",
    "job4 = {}\n",
    "job4['job_id'] = 'vader_two_cities'\n",
    "job4['bucket'] = bucket_name\n",
    "job4['utterance_file'] = 'darth.mp3'\n",
    "job4['sentences'] = two_cities_text\n",
    "\n",
    "job_json['jobs'] = [job1, job2, job3, job4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add our job as a json file to S3\n",
    "with open('./data/sample_job.json', 'w') as f:\n",
    "    f.write(json.dumps(job_json, indent=4))\n",
    "\n",
    "s3.Object(bucket_name, 'sample_job.json').upload_file('./data/sample_job.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................\u001b[34m2020/04/22 21:53:13 [notice] 10#10: using the \"epoll\" event method\u001b[0m\n",
      "\u001b[34m2020/04/22 21:53:13 [notice] 10#10: nginx/1.14.0 (Ubuntu)\u001b[0m\n",
      "\u001b[34m2020/04/22 21:53:13 [notice] 10#10: OS: Linux 4.14.165-103.209.amzn1.x86_64\u001b[0m\n",
      "\u001b[34m2020/04/22 21:53:13 [notice] 10#10: getrlimit(RLIMIT_NOFILE): 65536:99999\u001b[0m\n",
      "\u001b[34m2020/04/22 21:53:13 [notice] 10#10: start worker processes\u001b[0m\n",
      "\u001b[34m2020/04/22 21:53:13 [notice] 10#10: start worker process 12\u001b[0m\n",
      "\u001b[34m2020/04/22 21:53:13 [crit] 12#12: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [22/Apr/2020:21:53:13 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/04/22 21:53:14 [crit] 12#12: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m2020/04/22 21:53:13 [notice] 10#10: using the \"epoll\" event method\u001b[0m\n",
      "\u001b[35m2020/04/22 21:53:13 [notice] 10#10: nginx/1.14.0 (Ubuntu)\u001b[0m\n",
      "\u001b[35m2020/04/22 21:53:13 [notice] 10#10: OS: Linux 4.14.165-103.209.amzn1.x86_64\u001b[0m\n",
      "\u001b[35m2020/04/22 21:53:13 [notice] 10#10: getrlimit(RLIMIT_NOFILE): 65536:99999\u001b[0m\n",
      "\u001b[35m2020/04/22 21:53:13 [notice] 10#10: start worker processes\u001b[0m\n",
      "\u001b[35m2020/04/22 21:53:13 [notice] 10#10: start worker process 12\u001b[0m\n",
      "\u001b[35m2020/04/22 21:53:13 [crit] 12#12: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [22/Apr/2020:21:53:13 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/04/22 21:53:14 [crit] 12#12: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [22/Apr/2020:21:53:14 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/04/22 21:53:14 [crit] 12#12: *5 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [22/Apr/2020:21:53:14 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2020-04-22 21:53:14 +0000] [11] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2020-04-22 21:53:14 +0000] [11] [INFO] Listening at: unix:/tmp/gunicorn.sock (11)\u001b[0m\n",
      "\u001b[34m[2020-04-22 21:53:14 +0000] [11] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-04-22 21:53:14 +0000] [15] [INFO] Booting worker with pid: 15\u001b[0m\n",
      "\u001b[34m[2020-04-22 21:53:14 +0000] [16] [INFO] Booting worker with pid: 16\u001b[0m\n",
      "\u001b[34m[2020-04-22 21:53:14 +0000] [17] [INFO] Booting worker with pid: 17\u001b[0m\n",
      "\u001b[34m[2020-04-22 21:53:14 +0000] [18] [INFO] Booting worker with pid: 18\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [22/Apr/2020:21:53:14 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/04/22 21:53:14 [crit] 12#12: *5 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [22/Apr/2020:21:53:14 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2020-04-22 21:53:14 +0000] [11] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[35m[2020-04-22 21:53:14 +0000] [11] [INFO] Listening at: unix:/tmp/gunicorn.sock (11)\u001b[0m\n",
      "\u001b[35m[2020-04-22 21:53:14 +0000] [11] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2020-04-22 21:53:14 +0000] [15] [INFO] Booting worker with pid: 15\u001b[0m\n",
      "\u001b[35m[2020-04-22 21:53:14 +0000] [16] [INFO] Booting worker with pid: 16\u001b[0m\n",
      "\u001b[35m[2020-04-22 21:53:14 +0000] [17] [INFO] Booting worker with pid: 17\u001b[0m\n",
      "\u001b[35m[2020-04-22 21:53:14 +0000] [18] [INFO] Booting worker with pid: 18\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/synthesizer/models/modules.py:91: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/synthesizer/models/modules.py:91: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\n",
      "\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/synthesizer/models/modules.py:91: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/synthesizer/models/modules.py:91: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\n",
      "\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/synthesizer/models/modules.py:91: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/synthesizer/models/modules.py:91: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\n",
      "\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/synthesizer/models/modules.py:91: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\n",
      "\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/synthesizer/models/modules.py:91: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\n",
      "\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [22/Apr/2020:21:53:23 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [22/Apr/2020:21:53:23 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/04/22 21:53:23 [info] 12#12: *9 client 169.254.255.130 closed keepalive connection\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\u001b[0m\n",
      "\u001b[34mImport requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\u001b[0m\n",
      "\u001b[34mImport of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\u001b[0m\n",
      "\u001b[34m[2020-04-22 21:53:23,476] WARNING in process_voice: Starting request: test...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [22/Apr/2020:21:53:23 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [22/Apr/2020:21:53:23 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/04/22 21:53:23 [info] 12#12: *9 client 169.254.255.130 closed keepalive connection\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\u001b[0m\n",
      "\u001b[35mImport requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\u001b[0m\n",
      "\u001b[35mImport of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\u001b[0m\n",
      "\u001b[35m[2020-04-22 21:53:23,476] WARNING in process_voice: Starting request: test...\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/synthesizer/inference.py:57: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/synthesizer/tacotron2.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/synthesizer/tacotron2.py:21: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/synthesizer/models/tacotron.py:86: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mtf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/synthesizer/models/tacotron.py:123: The name tf.train.replica_device_setter is deprecated. Please use tf.compat.v1.train.replica_device_setter instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/synthesizer/models/tacotron.py:135: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCall initializer instance with the dtype argument instead of passing it to the constructor\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/synthesizer/models/modules.py:112: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThis class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/synthesizer/models/modules.py:421: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.keras.layers.Conv1D` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/synthesizer/models/modules.py:422: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/synthesizer/models/modules.py:425: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse keras.layers.dropout instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/synthesizer/models/modules.py:236: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/synthesizer/inference.py:57: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/synthesizer/tacotron2.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/synthesizer/tacotron2.py:21: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/synthesizer/models/tacotron.py:86: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mtf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/synthesizer/models/tacotron.py:123: The name tf.train.replica_device_setter is deprecated. Please use tf.compat.v1.train.replica_device_setter instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/synthesizer/models/tacotron.py:135: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mCall initializer instance with the dtype argument instead of passing it to the constructor\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/synthesizer/models/modules.py:112: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mThis class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/synthesizer/models/modules.py:421: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse `tf.keras.layers.Conv1D` instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/synthesizer/models/modules.py:422: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/synthesizer/models/modules.py:425: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse keras.layers.dropout instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/synthesizer/models/modules.py:236: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mPlease use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mPlease use `keras.layers.RNN(cell)`, which is equivalent to this API\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCall initializer instance with the dtype argument instead of passing it to the constructor\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mPlease use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mPlease use `keras.layers.RNN(cell)`, which is equivalent to this API\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mCall initializer instance with the dtype argument instead of passing it to the constructor\u001b[0m\n",
      "\u001b[32m2020-04-22T21:53:23.434:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/synthesizer/models/modules.py:156: The name tf.nn.rnn_cell.LSTMStateTuple is deprecated. Please use tf.compat.v1.nn.rnn_cell.LSTMStateTuple instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/synthesizer/models/attention.py:158: The name tf.layers.Conv1D is deprecated. Please use tf.compat.v1.layers.Conv1D instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/synthesizer/models/attention.py:161: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/synthesizer/models/modules.py:305: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThis class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/synthesizer/models/modules.py:156: The name tf.nn.rnn_cell.LSTMStateTuple is deprecated. Please use tf.compat.v1.nn.rnn_cell.LSTMStateTuple instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/synthesizer/models/attention.py:158: The name tf.layers.Conv1D is deprecated. Please use tf.compat.v1.layers.Conv1D instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/synthesizer/models/attention.py:161: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/synthesizer/models/modules.py:305: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mThis class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/synthesizer/models/modules.py:269: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse keras.layers.dense instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Entity <bound method ZoneoutLSTMCell.__call__ of <synthesizer.models.modules.ZoneoutLSTMCell object at 0x7f63e73178d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ZoneoutLSTMCell.__call__ of <synthesizer.models.modules.ZoneoutLSTMCell object at 0x7f63e73178d0>>: ValueError: Failed to parse source code of <bound method ZoneoutLSTMCell.__call__ of <synthesizer.models.modules.ZoneoutLSTMCell object at 0x7f63e73178d0>>, which Python reported as:\n",
      "    def __call__(self, inputs, state, scope=None):\n",
      "        \"\"\"Runs vanilla LSTM Cell and applies zoneout.\n",
      "        \"\"\"\n",
      "        # Apply vanilla LSTM\n",
      "        output, new_state = self._cell(inputs, state, scope)\n",
      "\n",
      "        if self.state_is_tuple:\n",
      "            (prev_c, prev_h) = state\n",
      "            (new_c, new_h) = new_state\n",
      "        else:\n",
      "            num_proj = self._cell._num_units if self._cell._num_proj is None else \\\u001b[0m\n",
      "\u001b[34m#011#011#011#011self._cell._num_proj\n",
      "            prev_c = tf.slice(state, [0, 0], [-1, self._cell._num_units])\n",
      "            prev_h = tf.slice(state, [0, self._cell._num_units], [-1, num_proj])\n",
      "            new_c = tf.slice(new_state, [0, 0], [-1, self._cell._num_units])\n",
      "            new_h = tf.slice(new_state, [0, self._cell._num_units], [-1, num_proj])\n",
      "\n",
      "        # Apply zoneout\n",
      "        if self.is_training:\n",
      "            # nn.dropout takes keep_prob (probability to keep activations) not drop_prob (\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/synthesizer/models/modules.py:269: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse keras.layers.dense instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:Entity <bound method ZoneoutLSTMCell.__call__ of <synthesizer.models.modules.ZoneoutLSTMCell object at 0x7f63e73178d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ZoneoutLSTMCell.__call__ of <synthesizer.models.modules.ZoneoutLSTMCell object at 0x7f63e73178d0>>: ValueError: Failed to parse source code of <bound method ZoneoutLSTMCell.__call__ of <synthesizer.models.modules.ZoneoutLSTMCell object at 0x7f63e73178d0>>, which Python reported as:\n",
      "    def __call__(self, inputs, state, scope=None):\n",
      "        \"\"\"Runs vanilla LSTM Cell and applies zoneout.\n",
      "        \"\"\"\n",
      "        # Apply vanilla LSTM\n",
      "        output, new_state = self._cell(inputs, state, scope)\n",
      "\n",
      "        if self.state_is_tuple:\n",
      "            (prev_c, prev_h) = state\n",
      "            (new_c, new_h) = new_state\n",
      "        else:\n",
      "            num_proj = self._cell._num_units if self._cell._num_proj is None else \\\u001b[0m\n",
      "\u001b[35m#011#011#011#011self._cell._num_proj\n",
      "            prev_c = tf.slice(state, [0, 0], [-1, self._cell._num_units])\n",
      "            prev_h = tf.slice(state, [0, self._cell._num_units], [-1, num_proj])\n",
      "            new_c = tf.slice(new_state, [0, 0], [-1, self._cell._num_units])\n",
      "            new_h = tf.slice(new_state, [0, self._cell._num_units], [-1, num_proj])\n",
      "\n",
      "        # Apply zoneout\n",
      "        if self.is_training:\n",
      "            # nn.dropout takes keep_prob (probability to keep activations) not drop_prob (\u001b[0m\n",
      "\u001b[34m#011#011#011# probability to mask activations)!\n",
      "            c = (1 - self._zoneout_cell) * tf.nn.dropout(new_c - prev_c,\n",
      "                                                         (1 - self._zoneout_cell)) + prev_c\n",
      "            h = (1 - self._zoneout_outputs) * tf.nn.dropout(new_h - prev_h,\n",
      "                                                            (1 - self._zoneout_outputs)) + prev_h\n",
      "\n",
      "        else:\n",
      "            c = (1 - self._zoneout_cell) * new_c + self._zoneout_cell * prev_c\n",
      "            h = (1 - self._zoneout_outputs) * new_h + self._zoneout_outputs * prev_h\n",
      "\n",
      "        new_state = tf.nn.rnn_cell.LSTMStateTuple(c, h) if self.state_is_tuple else tf.concat(1, [c,\n",
      "                                                                                                  h])\n",
      "\n",
      "        return output, new_state\n",
      "\u001b[0m\n",
      "\u001b[34mThis may be caused by multiline strings or comments not indented at the same level as the code.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Entity <bound method ZoneoutLSTMCell.__call__ of <synthesizer.models.modules.ZoneoutLSTMCell object at 0x7f63e64e6910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ZoneoutLSTMCell.__call__ of <synthesizer.models.modules.ZoneoutLSTMCell object at 0x7f63e64e6910>>: ValueError: Failed to parse source code of <bound method ZoneoutLSTMCell.__call__ of <synthesizer.models.modules.ZoneoutLSTMCell object at 0x7f63e64e6910>>, which Python reported as:\n",
      "    def __call__(self, inputs, state, scope=None):\n",
      "        \"\"\"Runs vanilla LSTM Cell and applies zoneout.\n",
      "        \"\"\"\n",
      "        # Apply vanilla LSTM\n",
      "        output, new_state = self._cell(inputs, state, scope)\n",
      "\n",
      "        if self.state_is_tuple:\n",
      "            (prev_c, prev_h) = state\n",
      "            (new_c, new_h) = new_state\n",
      "        else:\n",
      "            num_proj = self._cell._num_units if self._cell._num_proj is None else \\\u001b[0m\n",
      "\u001b[34m#011#011#011#011self._cell._num_proj\n",
      "            prev_c = tf.slice(state, [0, 0], [-1, self._cell._num_units])\n",
      "            prev_h = tf.slice(state, [0, self._cell._num_units], [-1, num_proj])\n",
      "            new_c = tf.slice(new_state, [0, 0], [-1, self._cell._num_units])\n",
      "            new_h = tf.slice(new_state, [0, self._cell._num_units], [-1, num_proj])\n",
      "\n",
      "        # Apply zoneout\n",
      "        if self.is_training:\n",
      "            # nn.dropout takes keep_prob (probability to keep activations) not drop_prob (\u001b[0m\n",
      "\u001b[34m#011#011#011# probability to mask activations)!\n",
      "            c = (1 - self._zoneout_cell) * tf.nn.dropout(new_c - prev_c,\n",
      "                                                         (1 - self._zoneout_cell)) + prev_c\n",
      "            h = (1 - self._zoneout_outputs) * tf.nn.dropout(new_h - prev_h,\n",
      "                                                            (1 - self._zoneout_outputs)) + prev_h\n",
      "\n",
      "        else:\n",
      "            c = (1 - self._zoneout_cell) * new_c + self._zoneout_cell * prev_c\n",
      "            h = (1 - self._zoneout_outputs) * new_h + self._zoneout_outputs * prev_h\n",
      "\n",
      "        new_state = tf.nn.rnn_cell.LSTMStateTuple(c, h) if self.state_is_tuple else tf.concat(1, [c,\n",
      "                                                                                                  h])\n",
      "\n",
      "        return output, new_state\n",
      "\u001b[0m\n",
      "\u001b[34mThis may be caused by multiline strings or comments not indented at the same level as the code.\u001b[0m\n",
      "\u001b[35m#011#011#011# probability to mask activations)!\n",
      "            c = (1 - self._zoneout_cell) * tf.nn.dropout(new_c - prev_c,\n",
      "                                                         (1 - self._zoneout_cell)) + prev_c\n",
      "            h = (1 - self._zoneout_outputs) * tf.nn.dropout(new_h - prev_h,\n",
      "                                                            (1 - self._zoneout_outputs)) + prev_h\n",
      "\n",
      "        else:\n",
      "            c = (1 - self._zoneout_cell) * new_c + self._zoneout_cell * prev_c\n",
      "            h = (1 - self._zoneout_outputs) * new_h + self._zoneout_outputs * prev_h\n",
      "\n",
      "        new_state = tf.nn.rnn_cell.LSTMStateTuple(c, h) if self.state_is_tuple else tf.concat(1, [c,\n",
      "                                                                                                  h])\n",
      "\n",
      "        return output, new_state\n",
      "\u001b[0m\n",
      "\u001b[35mThis may be caused by multiline strings or comments not indented at the same level as the code.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:Entity <bound method ZoneoutLSTMCell.__call__ of <synthesizer.models.modules.ZoneoutLSTMCell object at 0x7f63e64e6910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ZoneoutLSTMCell.__call__ of <synthesizer.models.modules.ZoneoutLSTMCell object at 0x7f63e64e6910>>: ValueError: Failed to parse source code of <bound method ZoneoutLSTMCell.__call__ of <synthesizer.models.modules.ZoneoutLSTMCell object at 0x7f63e64e6910>>, which Python reported as:\n",
      "    def __call__(self, inputs, state, scope=None):\n",
      "        \"\"\"Runs vanilla LSTM Cell and applies zoneout.\n",
      "        \"\"\"\n",
      "        # Apply vanilla LSTM\n",
      "        output, new_state = self._cell(inputs, state, scope)\n",
      "\n",
      "        if self.state_is_tuple:\n",
      "            (prev_c, prev_h) = state\n",
      "            (new_c, new_h) = new_state\n",
      "        else:\n",
      "            num_proj = self._cell._num_units if self._cell._num_proj is None else \\\u001b[0m\n",
      "\u001b[35m#011#011#011#011self._cell._num_proj\n",
      "            prev_c = tf.slice(state, [0, 0], [-1, self._cell._num_units])\n",
      "            prev_h = tf.slice(state, [0, self._cell._num_units], [-1, num_proj])\n",
      "            new_c = tf.slice(new_state, [0, 0], [-1, self._cell._num_units])\n",
      "            new_h = tf.slice(new_state, [0, self._cell._num_units], [-1, num_proj])\n",
      "\n",
      "        # Apply zoneout\n",
      "        if self.is_training:\n",
      "            # nn.dropout takes keep_prob (probability to keep activations) not drop_prob (\u001b[0m\n",
      "\u001b[35m#011#011#011# probability to mask activations)!\n",
      "            c = (1 - self._zoneout_cell) * tf.nn.dropout(new_c - prev_c,\n",
      "                                                         (1 - self._zoneout_cell)) + prev_c\n",
      "            h = (1 - self._zoneout_outputs) * tf.nn.dropout(new_h - prev_h,\n",
      "                                                            (1 - self._zoneout_outputs)) + prev_h\n",
      "\n",
      "        else:\n",
      "            c = (1 - self._zoneout_cell) * new_c + self._zoneout_cell * prev_c\n",
      "            h = (1 - self._zoneout_outputs) * new_h + self._zoneout_outputs * prev_h\n",
      "\n",
      "        new_state = tf.nn.rnn_cell.LSTMStateTuple(c, h) if self.state_is_tuple else tf.concat(1, [c,\n",
      "                                                                                                  h])\n",
      "\n",
      "        return output, new_state\n",
      "\u001b[0m\n",
      "\u001b[35mThis may be caused by multiline strings or comments not indented at the same level as the code.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/synthesizer/models/tacotron.py:286: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/synthesizer/models/tacotron.py:286: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2020-04-22 21:53:27.796567: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[34m2020-04-22 21:53:27.818817: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300080000 Hz\u001b[0m\n",
      "\u001b[34m2020-04-22 21:53:27.819144: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5616425a2b50 executing computations on platform Host. Devices:\u001b[0m\n",
      "\u001b[34m2020-04-22 21:53:27.819168: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\u001b[0m\n",
      "\u001b[34m2020-04-22 21:53:27.819365: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\u001b[0m\n",
      "\u001b[34m2020-04-22 21:53:27.819569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2020-04-22 21:53:27.820336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \u001b[0m\n",
      "\u001b[34mname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8755\u001b[0m\n",
      "\u001b[34mpciBusID: 0000:00:1e.0\u001b[0m\n",
      "\u001b[34m2020-04-22 21:53:27.820614: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\u001b[0m\n",
      "\u001b[34m2020-04-22 21:53:27.820784: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\u001b[0m\n",
      "\u001b[34m2020-04-22 21:53:27.820944: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\u001b[0m\n",
      "\u001b[34m2020-04-22 21:53:27.821098: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\u001b[0m\n",
      "\u001b[34m2020-04-22 21:53:27.821253: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\u001b[0m\n",
      "\u001b[34m2020-04-22 21:53:27.821407: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\u001b[0m\n",
      "\u001b[34m2020-04-22 21:53:27.821559: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\u001b[0m\n",
      "\u001b[34m2020-04-22 21:53:27.821579: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1663] Cannot dlopen some GPU libraries. Skipping registering GPU devices...\u001b[0m\n",
      "\u001b[34m2020-04-22 21:53:27.821724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\u001b[0m\n",
      "\u001b[34m2020-04-22 21:53:27.821749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \u001b[0m\n",
      "\u001b[34m2020-04-22 21:53:27.821760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \u001b[0m\n",
      "\u001b[34m2020-04-22 21:53:27.823162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2020-04-22 21:53:27.823941: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561612c88ae0 executing computations on platform CUDA. Devices:\u001b[0m\n",
      "\u001b[34m2020-04-22 21:53:27.823966: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\u001b[0m\n",
      "\u001b[34m2020-04-22 21:53:28.006473: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/synthesizer/tacotron2.py:62: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35m2020-04-22 21:53:27.796567: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[35m2020-04-22 21:53:27.818817: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300080000 Hz\u001b[0m\n",
      "\u001b[35m2020-04-22 21:53:27.819144: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5616425a2b50 executing computations on platform Host. Devices:\u001b[0m\n",
      "\u001b[35m2020-04-22 21:53:27.819168: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\u001b[0m\n",
      "\u001b[35m2020-04-22 21:53:27.819365: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\u001b[0m\n",
      "\u001b[35m2020-04-22 21:53:27.819569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[35m2020-04-22 21:53:27.820336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \u001b[0m\n",
      "\u001b[35mname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8755\u001b[0m\n",
      "\u001b[35mpciBusID: 0000:00:1e.0\u001b[0m\n",
      "\u001b[35m2020-04-22 21:53:27.820614: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\u001b[0m\n",
      "\u001b[35m2020-04-22 21:53:27.820784: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\u001b[0m\n",
      "\u001b[35m2020-04-22 21:53:27.820944: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\u001b[0m\n",
      "\u001b[35m2020-04-22 21:53:27.821098: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\u001b[0m\n",
      "\u001b[35m2020-04-22 21:53:27.821253: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\u001b[0m\n",
      "\u001b[35m2020-04-22 21:53:27.821407: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\u001b[0m\n",
      "\u001b[35m2020-04-22 21:53:27.821559: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\u001b[0m\n",
      "\u001b[35m2020-04-22 21:53:27.821579: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1663] Cannot dlopen some GPU libraries. Skipping registering GPU devices...\u001b[0m\n",
      "\u001b[35m2020-04-22 21:53:27.821724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\u001b[0m\n",
      "\u001b[35m2020-04-22 21:53:27.821749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \u001b[0m\n",
      "\u001b[35m2020-04-22 21:53:27.821760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \u001b[0m\n",
      "\u001b[35m2020-04-22 21:53:27.823162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[35m2020-04-22 21:53:27.823941: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561612c88ae0 executing computations on platform CUDA. Devices:\u001b[0m\n",
      "\u001b[35m2020-04-22 21:53:27.823966: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\u001b[0m\n",
      "\u001b[35m2020-04-22 21:53:28.006473: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/synthesizer/tacotron2.py:62: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse standard file APIs to check for files with this prefix.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse standard file APIs to check for files with this prefix.\u001b[0m\n",
      "\u001b[34mBuilding Wave-RNN\u001b[0m\n",
      "\u001b[34mTrainable Parameters: 4.481M\u001b[0m\n",
      "\u001b[34mLoading model weights at /opt/ml/model/vocoder/saved_models/pretrained/pretrained.pt\u001b[0m\n",
      "\u001b[34mConstructing model: Tacotron\u001b[0m\n",
      "\u001b[34minitialisation done /gpu:0\u001b[0m\n",
      "\u001b[34mInitialized Tacotron model. Dimensions (? = dynamic shape): \n",
      "  Train mode:               False\n",
      "  Eval mode:                False\n",
      "  GTA mode:                 False\n",
      "  Synthesis mode:           True\n",
      "  Input:                    (?, ?)\n",
      "  device:                   0\n",
      "  embedding:                (?, ?, 512)\n",
      "  enc conv out:             (?, ?, 512)\n",
      "  encoder out (cond):       (?, ?, 768)\n",
      "  decoder out:              (?, ?, 80)\n",
      "  residual out:             (?, ?, 512)\n",
      "  projected residual out:   (?, ?, 80)\n",
      "  mel out:                  (?, ?, 80)\n",
      "  <stop_token> out:         (?, ?)\n",
      "  Tacotron Parameters       28.439 Million.\u001b[0m\n",
      "\u001b[34mLoading checkpoint: /opt/ml/model/synthesizer/saved_models/logs-pretrained/taco_pretrained/tacotron_model.ckpt-278000\u001b[0m\n",
      "\u001b[35mBuilding Wave-RNN\u001b[0m\n",
      "\u001b[35mTrainable Parameters: 4.481M\u001b[0m\n",
      "\u001b[35mLoading model weights at /opt/ml/model/vocoder/saved_models/pretrained/pretrained.pt\u001b[0m\n",
      "\u001b[35mConstructing model: Tacotron\u001b[0m\n",
      "\u001b[35minitialisation done /gpu:0\u001b[0m\n",
      "\u001b[35mInitialized Tacotron model. Dimensions (? = dynamic shape): \n",
      "  Train mode:               False\n",
      "  Eval mode:                False\n",
      "  GTA mode:                 False\n",
      "  Synthesis mode:           True\n",
      "  Input:                    (?, ?)\n",
      "  device:                   0\n",
      "  embedding:                (?, ?, 512)\n",
      "  enc conv out:             (?, ?, 512)\n",
      "  encoder out (cond):       (?, ?, 768)\n",
      "  decoder out:              (?, ?, 80)\n",
      "  residual out:             (?, ?, 512)\n",
      "  projected residual out:   (?, ?, 80)\n",
      "  mel out:                  (?, ?, 80)\n",
      "  <stop_token> out:         (?, ?)\n",
      "  Tacotron Parameters       28.439 Million.\u001b[0m\n",
      "\u001b[35mLoading checkpoint: /opt/ml/model/synthesizer/saved_models/logs-pretrained/taco_pretrained/tacotron_model.ckpt-278000\u001b[0m\n",
      "\u001b[34m/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  43200/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  44100/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  45000/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  45900/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  46800/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  47700/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  48600/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  49500/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  50400/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  51300/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  52200/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  53100/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  54000/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  54900/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  55800/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  56700/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  57600/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  58500/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  59400/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  60300/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  61200/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  62100/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  63000/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  63900/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  64800/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  65700/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  66600/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  67500/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  68400/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  69300/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  70200/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  71100/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  72000/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  72900/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  73800/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  74700/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  75600/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  76500/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  77400/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  78300/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  79200/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  80100/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  81000/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  81900/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  82800/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  83700/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  84600/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  85500/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  0/96000 | Batch Size: 10 | Gen Rate: 0.1kHz | }#015{|  1000/96000 | Batch Size: 10 | Gen Rate: 5.3kHz | }#015{|  2000/96000 | Batch Size: 10 | Gen Rate: 6.9kHz | }#015{|  3000/96000 | Batch Size: 10 | Gen Rate: 7.8kHz | }#015{|  4000/96000 | Batch Size: 10 | Gen Rate: 8.3kHz | }#015{|  5000/96000 | Batch Size: 10 | Gen Rate: 8.6kHz | }#015{|  6000/96000 | Batch Size: 10 | Gen Rate: 8.9kHz | }#015{|  7000/96000 | Batch Size: 10 | Gen Rate: 9.1kHz | }#015{|  8000/96000 | Batch Size: 10 | Gen Rate: 9.2kHz | }#015{|  9000/96000 | Batch Size: 10 | Gen Rate: 9.4kHz | }#015{|  10000/96000 | Batch Size: 10 | Gen Rate: 9.5kHz | }#015{|  11000/96000 | Batch Size: 10 | Gen Rate: 9.6kHz | }#015{|  12000/96000 | Batch Size: 10 | Gen Rate: 9.6kHz | }#015{|  13000/96000 | Batch Size: 10 | Gen Rate: 9.7kHz | }#015{|  14000/96000 | Batch Size: 10 | Gen Rate: 9.8kHz | }#015{|  15000/96000 | Batch Size: 10 | Gen Rate: 9.8kHz | }#015{|  16000/96000 | Batch Size: 10 | Gen Rate: 9.8kHz | }#015{|  17000/96000 | Batch Size: 10 | Gen Rate: 9.9kHz | }#015{|  18000/96000 | Batch Size: 10 | Gen Rate: 9.9kHz | }#015{|  19000/96000 | Batch Size: 10 | Gen Rate: 9.9kHz | }#015{|  20000/96000 | Batch Size: 10 | Gen Rate: 10.0kHz | }#015{|  21000/96000 | Batch Size: 10 | Gen Rate: 10.0kHz | }#015{|  22000/96000 | Batch Size: 10 | Gen Rate: 10.0kHz | }#015{|  23000/96000 | Batch Size: 10 | Gen Rate: 10.0kHz | }#015{|  24000/96000 | Batch Size: 10 | Gen Rate: 10.0kHz | }#015{|  25000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  26000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  27000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  28000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  29000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  30000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  31000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  32000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  33000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  34000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  35000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  36000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  37000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  38000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  39000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  40000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  41000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  42000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  43000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  44000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  45000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  46000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  47000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  48000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  49000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  50000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  51000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  52000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  53000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  54000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  55000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  56000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  57000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  58000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  59000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  60000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  61000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  62000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  63000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  64000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  65000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  66000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  67000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  68000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  69000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  70000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  71000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  72000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  73000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  74000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  75000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  76000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  77000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  78000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  79000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  80000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  81000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  82000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  83000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  84000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  85000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  86000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  87000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  88000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  89000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  90000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  91000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  92000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  93000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  94000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  95000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  0/144000 | Batch Size: 15 | Gen Rate: 0.1kHz | }#015{|  1500/144000 | Batch Size: 15 | Gen Rate: 6.3kHz | }#015{|  3000/144000 | Batch Size: 15 | Gen Rate: 8.9kHz | }#015{|  4500/144000 | Batch Size: 15 | Gen Rate: 10.4kHz | }#015{|  6000/144000 | Batch Size: 15 | Gen Rate: 11.3kHz | }#015{|  7500/144000 | Batch Size: 15 | Gen Rate: 12.0kHz | }#015{|  9000/144000 | Batch Size: 15 | Gen Rate: 12.4kHz | }#015{|  10500/144000 | Batch Size: 15 | Gen Rate: 12.8kHz | }#015{|  12000/144000 | Batch Size: 15 | Gen Rate: 13.1kHz | }#015{|  13500/144000 | Batch Size: 15 | Gen Rate: 13.3kHz | }#015{|  15000/144000 | Batch Size: 15 | Gen Rate: 13.5kHz | }#015{|  16500/144000 | Batch Size: 15 | Gen Rate: 13.7kHz | }#015{|  18000/144000 | Batch Size: 15 | Gen \u001b[0m\n",
      "\u001b[35m/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  43200/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  44100/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  45000/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  45900/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  46800/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  47700/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  48600/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  49500/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  50400/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  51300/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  52200/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  53100/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  54000/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  54900/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  55800/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  56700/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  57600/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  58500/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  59400/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  60300/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  61200/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  62100/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  63000/86400 | Batch Size: 9 | Gen Rate: 9.2kHz | }#015{|  63900/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  64800/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  65700/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  66600/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  67500/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  68400/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  69300/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  70200/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  71100/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  72000/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  72900/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  73800/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  74700/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  75600/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  76500/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  77400/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  78300/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  79200/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  80100/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  81000/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  81900/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  82800/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  83700/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  84600/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  85500/86400 | Batch Size: 9 | Gen Rate: 9.3kHz | }#015{|  0/96000 | Batch Size: 10 | Gen Rate: 0.1kHz | }#015{|  1000/96000 | Batch Size: 10 | Gen Rate: 5.3kHz | }#015{|  2000/96000 | Batch Size: 10 | Gen Rate: 6.9kHz | }#015{|  3000/96000 | Batch Size: 10 | Gen Rate: 7.8kHz | }#015{|  4000/96000 | Batch Size: 10 | Gen Rate: 8.3kHz | }#015{|  5000/96000 | Batch Size: 10 | Gen Rate: 8.6kHz | }#015{|  6000/96000 | Batch Size: 10 | Gen Rate: 8.9kHz | }#015{|  7000/96000 | Batch Size: 10 | Gen Rate: 9.1kHz | }#015{|  8000/96000 | Batch Size: 10 | Gen Rate: 9.2kHz | }#015{|  9000/96000 | Batch Size: 10 | Gen Rate: 9.4kHz | }#015{|  10000/96000 | Batch Size: 10 | Gen Rate: 9.5kHz | }#015{|  11000/96000 | Batch Size: 10 | Gen Rate: 9.6kHz | }#015{|  12000/96000 | Batch Size: 10 | Gen Rate: 9.6kHz | }#015{|  13000/96000 | Batch Size: 10 | Gen Rate: 9.7kHz | }#015{|  14000/96000 | Batch Size: 10 | Gen Rate: 9.8kHz | }#015{|  15000/96000 | Batch Size: 10 | Gen Rate: 9.8kHz | }#015{|  16000/96000 | Batch Size: 10 | Gen Rate: 9.8kHz | }#015{|  17000/96000 | Batch Size: 10 | Gen Rate: 9.9kHz | }#015{|  18000/96000 | Batch Size: 10 | Gen Rate: 9.9kHz | }#015{|  19000/96000 | Batch Size: 10 | Gen Rate: 9.9kHz | }#015{|  20000/96000 | Batch Size: 10 | Gen Rate: 10.0kHz | }#015{|  21000/96000 | Batch Size: 10 | Gen Rate: 10.0kHz | }#015{|  22000/96000 | Batch Size: 10 | Gen Rate: 10.0kHz | }#015{|  23000/96000 | Batch Size: 10 | Gen Rate: 10.0kHz | }#015{|  24000/96000 | Batch Size: 10 | Gen Rate: 10.0kHz | }#015{|  25000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  26000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  27000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  28000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  29000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  30000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  31000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  32000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  33000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  34000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  35000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  36000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  37000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  38000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  39000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  40000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  41000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  42000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  43000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  44000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  45000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  46000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  47000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  48000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  49000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  50000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  51000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  52000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  53000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  54000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  55000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  56000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  57000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  58000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  59000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  60000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  61000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  62000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  63000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  64000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  65000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  66000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  67000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  68000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  69000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  70000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  71000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  72000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  73000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  74000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  75000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  76000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  77000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  78000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  79000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  80000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  81000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  82000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  83000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  84000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  85000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  86000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  87000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  88000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  89000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  90000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  91000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  92000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  93000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  94000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  95000/96000 | Batch Size: 10 | Gen Rate: 10.3kHz | }#015{|  0/144000 | Batch Size: 15 | Gen Rate: 0.1kHz | }#015{|  1500/144000 | Batch Size: 15 | Gen Rate: 6.3kHz | }#015{|  3000/144000 | Batch Size: 15 | Gen Rate: 8.9kHz | }#015{|  4500/144000 | Batch Size: 15 | Gen Rate: 10.4kHz | }#015{|  6000/144000 | Batch Size: 15 | Gen Rate: 11.3kHz | }#015{|  7500/144000 | Batch Size: 15 | Gen Rate: 12.0kHz | }#015{|  9000/144000 | Batch Size: 15 | Gen Rate: 12.4kHz | }#015{|  10500/144000 | Batch Size: 15 | Gen Rate: 12.8kHz | }#015{|  12000/144000 | Batch Size: 15 | Gen Rate: 13.1kHz | }#015{|  13500/144000 | Batch Size: 15 | Gen Rate: 13.3kHz | }#015{|  15000/144000 | Batch Size: 15 | Gen Rate: 13.5kHz | }#015{|  16500/144000 | Batch Size: 15 | Gen Rate: 13.7kHz | }#015{|  18000/144000 | Batch Size: 15 | Gen \u001b[0m\n",
      "\u001b[34m 72000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  73000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  74000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  75000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  76000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  77000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  78000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  79000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  80000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  81000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  82000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  83000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  84000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  85000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  86000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  87000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  88000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  89000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  90000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  91000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  92000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  93000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  94000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  95000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  0/105600 | Batch Size: 11 | Gen Rate: 0.1kHz | }#015{|  1100/105600 | Batch Size: 11 | Gen Rate: 5.4kHz | }#015{|  2200/105600 | Batch Size: 11 | Gen Rate: 7.3kHz | }#015{|  3300/105600 | Batch Size: 11 | Gen Rate: 8.3kHz | }#015{|  4400/105600 | Batch Size: 11 | Gen Rate: 8.9kHz | }#015{|  5500/105600 | Batch Size: 11 | Gen Rate: 9.3kHz | }#015{|  6600/105600 | Batch Size: 11 | Gen Rate: 9.6kHz | }#015{|  7700/105600 | Batch Size: 11 | Gen Rate: 9.9kHz | }#015{|  8800/105600 | Batch Size: 11 | Gen Rate: 10.0kHz | }#015{|  9900/105600 | Batch Size: 11 | Gen Rate: 10.2kHz | }#015{|  11000/105600 | Batch Size: 11 | Gen Rate: 10.3kHz | }#015{|  12100/105600 | Batch Size: 11 | Gen Rate: 10.4kHz | }#015{|  13200/105600 | Batch Size: 11 | Gen Rate: 10.5kHz | }#015{|  14300/105600 | Batch Size: 11 | Gen Rate: 10.6kHz | }#015{|  15400/105600 | Batch Size: 11 | Gen Rate: 10.6kHz | }#015{|  16500/105600 | Batch Size: 11 | Gen Rate: 10.7kHz | }#015{|  17600/105600 | Batch Size: 11 | Gen Rate: 10.7kHz | }#015{|  18700/105600 | Batch Size: 11 | Gen Rate: 10.8kHz | }#015{|  19800/105600 | Batch Size: 11 | Gen Rate: 10.8kHz | }#015{|  20900/105600 | Batch Size: 11 | Gen Rate: 10.8kHz | }#015{|  22000/105600 | Batch Size: 11 | Gen Rate: 10.9kHz | }#015{|  23100/105600 | Batch Size: 11 | Gen Rate: 10.9kHz | }#015{|  24200/105600 | Batch Size: 11 | Gen Rate: 10.9kHz | }#015{|  25300/105600 | Batch Size: 11 | Gen Rate: 10.9kHz | }#015{|  26400/105600 | Batch Size: 11 | Gen Rate: 11.0kHz | }#015{|  27500/105600 | Batch Size: 11 | Gen Rate: 11.0kHz | }#015{|  28600/105600 | Batch Size: 11 | Gen Rate: 11.0kHz | }#015{|  29700/105600 | Batch Size: 11 | Gen Rate: 11.0kHz | }#015{|  30800/105600 | Batch Size: 11 | Gen Rate: 11.0kHz | }#015{|  31900/105600 | Batch Size: 11 | Gen Rate: 11.0kHz | }#015{|  33000/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  34100/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  35200/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  36300/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  37400/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  38500/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  39600/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  40700/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  41800/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  42900/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  44000/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  45100/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  46200/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  47300/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  48400/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  49500/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  50600/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  51700/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  52800/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  53900/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  55000/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  56100/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  57200/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  58300/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  59400/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  60500/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  61600/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  62700/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  63800/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  64900/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  66000/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  67100/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  68200/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  69300/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  70400/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  71500/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  72600/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  73700/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  74800/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  75900/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  77000/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  78100/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  79200/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  80300/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  81400/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  82500/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  83600/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  84700/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  85800/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  86900/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  88000/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  89100/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  90200/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  91300/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  92400/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  93500/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  94600/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  95700/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  96800/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  97900/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  99000/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  100100/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  101200/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  102300/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  103400/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  104500/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  0/105600 | Batch Size: 11 | Gen Rate: 0.1kHz | }#015{|  1100/105600 | Batch Size: 11 | Gen Rate: 5.3kHz | }#015{|  2200/105600 | Batch Size: 11 | Gen Rate: 7.1kHz | }#015{|  3300/105600 | Batch Size: 11 | Gen Rate: 8.1kHz | }#015{|  4400/105600 | Batch Size: 11 | Gen Rate: 8.7kHz | }#015{|  5500/105600 | Batch Size: 11 | Gen Rate: 9.2kHz | }#015{|  6600/105600 | Batch Size: 11 | Gen Rate: 9.5kHz | }#015{|  7700/105600 | Batch Size: 11 | Gen Rate: 9.7kHz | }#015{|  8800/105600 | Batch Size: 11 | Gen Rate: 9.9kHz | }#015{|  9900/105600 | Batch Size: 11 | Gen Rate: 10.1kHz | }#015{|  11000/105600 | Batch Size: 11 | Gen Rate: 10.2kHz | }#015{|  12100/105600 | Batch Size: 11 | Gen Rate: 10.3kHz | }#015{|  13200/105600 | Batch Size: 11 | Gen Rate: 10.4kHz | }#015{|  14300/105600 | Batch Size: 11 | Gen Rate: 10.5kHz | }#015{|  15400/105600 | Batch Size: 11 | Gen Rate: 10.5kHz | }#015{|  16500/105600 | Batch Size: 11 | Gen Rate: 10.6kHz | }#015{|  17600/105600 | Batch Size: 11 | Gen Rate: 10.7kHz | }#015{|  18700/105600 | Batch Size: 11 | Gen Rate: 10.7kHz | }#015{|  19800/105600 | Batch Size: 11 | Gen Rate: 10.7kHz | }#015{|  20900/105600 | Batch Size: 11 | Gen Rate: 10.8kHz | }#015{|  22000/105600 | Batch Size: 11 | Gen Rate: 10.8kHz | }#015{|  23100/105600 | Batch Size: 11 | Gen Rate: 10.9kHz | }#015{|  24200/105600 | Batch Size: 11 | Gen Rate: 10.9kHz | }#015{|  25300/105600 | Batch Size: 11 | Gen Rate: 10.9kHz | }#015{|  26400/105600 | Batch Size: 11 | Gen Rate: 10.9kHz | }#015{|  27500/105600 | Batch Size: 11 | Gen Rate: 11.0kHz | }#015{|  28600/105600 | Batch Size: 11 | Gen Rate: 11.0kHz | }#015{|  29700/105600 | Batch Size: 11 | Gen Rate: 11.0kHz | }#015{|  30800/105600 | Batch Size: 11 | Gen Rate: 11.0kHz | }#015{|  31900/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  33000/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  34100/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  35200/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  36300/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  37400/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  38500/105\u001b[0m\n",
      "\u001b[35m 72000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  73000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  74000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  75000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  76000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  77000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  78000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  79000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  80000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  81000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  82000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  83000/96000 | Batch Size: 10 | Gen Rate: 10.1kHz | }#015{|  84000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  85000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  86000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  87000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  88000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  89000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  90000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  91000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  92000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  93000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  94000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  95000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }#015{|  0/105600 | Batch Size: 11 | Gen Rate: 0.1kHz | }#015{|  1100/105600 | Batch Size: 11 | Gen Rate: 5.4kHz | }#015{|  2200/105600 | Batch Size: 11 | Gen Rate: 7.3kHz | }#015{|  3300/105600 | Batch Size: 11 | Gen Rate: 8.3kHz | }#015{|  4400/105600 | Batch Size: 11 | Gen Rate: 8.9kHz | }#015{|  5500/105600 | Batch Size: 11 | Gen Rate: 9.3kHz | }#015{|  6600/105600 | Batch Size: 11 | Gen Rate: 9.6kHz | }#015{|  7700/105600 | Batch Size: 11 | Gen Rate: 9.9kHz | }#015{|  8800/105600 | Batch Size: 11 | Gen Rate: 10.0kHz | }#015{|  9900/105600 | Batch Size: 11 | Gen Rate: 10.2kHz | }#015{|  11000/105600 | Batch Size: 11 | Gen Rate: 10.3kHz | }#015{|  12100/105600 | Batch Size: 11 | Gen Rate: 10.4kHz | }#015{|  13200/105600 | Batch Size: 11 | Gen Rate: 10.5kHz | }#015{|  14300/105600 | Batch Size: 11 | Gen Rate: 10.6kHz | }#015{|  15400/105600 | Batch Size: 11 | Gen Rate: 10.6kHz | }#015{|  16500/105600 | Batch Size: 11 | Gen Rate: 10.7kHz | }#015{|  17600/105600 | Batch Size: 11 | Gen Rate: 10.7kHz | }#015{|  18700/105600 | Batch Size: 11 | Gen Rate: 10.8kHz | }#015{|  19800/105600 | Batch Size: 11 | Gen Rate: 10.8kHz | }#015{|  20900/105600 | Batch Size: 11 | Gen Rate: 10.8kHz | }#015{|  22000/105600 | Batch Size: 11 | Gen Rate: 10.9kHz | }#015{|  23100/105600 | Batch Size: 11 | Gen Rate: 10.9kHz | }#015{|  24200/105600 | Batch Size: 11 | Gen Rate: 10.9kHz | }#015{|  25300/105600 | Batch Size: 11 | Gen Rate: 10.9kHz | }#015{|  26400/105600 | Batch Size: 11 | Gen Rate: 11.0kHz | }#015{|  27500/105600 | Batch Size: 11 | Gen Rate: 11.0kHz | }#015{|  28600/105600 | Batch Size: 11 | Gen Rate: 11.0kHz | }#015{|  29700/105600 | Batch Size: 11 | Gen Rate: 11.0kHz | }#015{|  30800/105600 | Batch Size: 11 | Gen Rate: 11.0kHz | }#015{|  31900/105600 | Batch Size: 11 | Gen Rate: 11.0kHz | }#015{|  33000/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  34100/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  35200/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  36300/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  37400/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  38500/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  39600/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  40700/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  41800/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  42900/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  44000/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  45100/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  46200/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  47300/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  48400/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  49500/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  50600/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  51700/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  52800/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  53900/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  55000/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  56100/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  57200/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  58300/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  59400/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  60500/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  61600/105600 | Batch Size: 11 | Gen Rate: 11.2kHz | }#015{|  62700/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  63800/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  64900/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  66000/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  67100/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  68200/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  69300/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  70400/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  71500/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  72600/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  73700/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  74800/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  75900/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  77000/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  78100/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  79200/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  80300/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  81400/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  82500/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  83600/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  84700/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  85800/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  86900/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  88000/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  89100/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  90200/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  91300/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  92400/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  93500/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  94600/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  95700/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  96800/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  97900/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  99000/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  100100/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  101200/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  102300/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  103400/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  104500/105600 | Batch Size: 11 | Gen Rate: 11.3kHz | }#015{|  0/105600 | Batch Size: 11 | Gen Rate: 0.1kHz | }#015{|  1100/105600 | Batch Size: 11 | Gen Rate: 5.3kHz | }#015{|  2200/105600 | Batch Size: 11 | Gen Rate: 7.1kHz | }#015{|  3300/105600 | Batch Size: 11 | Gen Rate: 8.1kHz | }#015{|  4400/105600 | Batch Size: 11 | Gen Rate: 8.7kHz | }#015{|  5500/105600 | Batch Size: 11 | Gen Rate: 9.2kHz | }#015{|  6600/105600 | Batch Size: 11 | Gen Rate: 9.5kHz | }#015{|  7700/105600 | Batch Size: 11 | Gen Rate: 9.7kHz | }#015{|  8800/105600 | Batch Size: 11 | Gen Rate: 9.9kHz | }#015{|  9900/105600 | Batch Size: 11 | Gen Rate: 10.1kHz | }#015{|  11000/105600 | Batch Size: 11 | Gen Rate: 10.2kHz | }#015{|  12100/105600 | Batch Size: 11 | Gen Rate: 10.3kHz | }#015{|  13200/105600 | Batch Size: 11 | Gen Rate: 10.4kHz | }#015{|  14300/105600 | Batch Size: 11 | Gen Rate: 10.5kHz | }#015{|  15400/105600 | Batch Size: 11 | Gen Rate: 10.5kHz | }#015{|  16500/105600 | Batch Size: 11 | Gen Rate: 10.6kHz | }#015{|  17600/105600 | Batch Size: 11 | Gen Rate: 10.7kHz | }#015{|  18700/105600 | Batch Size: 11 | Gen Rate: 10.7kHz | }#015{|  19800/105600 | Batch Size: 11 | Gen Rate: 10.7kHz | }#015{|  20900/105600 | Batch Size: 11 | Gen Rate: 10.8kHz | }#015{|  22000/105600 | Batch Size: 11 | Gen Rate: 10.8kHz | }#015{|  23100/105600 | Batch Size: 11 | Gen Rate: 10.9kHz | }#015{|  24200/105600 | Batch Size: 11 | Gen Rate: 10.9kHz | }#015{|  25300/105600 | Batch Size: 11 | Gen Rate: 10.9kHz | }#015{|  26400/105600 | Batch Size: 11 | Gen Rate: 10.9kHz | }#015{|  27500/105600 | Batch Size: 11 | Gen Rate: 11.0kHz | }#015{|  28600/105600 | Batch Size: 11 | Gen Rate: 11.0kHz | }#015{|  29700/105600 | Batch Size: 11 | Gen Rate: 11.0kHz | }#015{|  30800/105600 | Batch Size: 11 | Gen Rate: 11.0kHz | }#015{|  31900/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  33000/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  34100/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  35200/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  36300/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  37400/105600 | Batch Size: 11 | Gen Rate: 11.1kHz | }#015{|  38500/105\u001b[0m\n",
      "\n",
      "\u001b[34m 112800/115200 | Batch Size: 12 | Gen Rate: 12.5kHz | }169.254.255.130 - - [22/Apr/2020:21:56:56 +0000] \"POST /invocations HTTP/1.1\" 200 13 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m 112800/115200 | Batch Size: 12 | Gen Rate: 12.5kHz | }169.254.255.130 - - [22/Apr/2020:21:56:56 +0000] \"POST /invocations HTTP/1.1\" 200 13 \"-\" \"Go-http-client/1.1\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Start the job. It should take several minutes. Although most of that is from starting the container.\n",
    "trans.transform(f's3://{bucket_name}/sample_job.json', content_type='application/json')\n",
    "trans.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: freeman_hp_0.wav\n",
      "Downloading: freeman_hp_1.wav\n",
      "Downloading: freeman_hp_2.wav\n",
      "Downloading: freeman_hp_3.wav\n",
      "Downloading: freeman_hp_4.wav\n",
      "Downloading: freeman_hp_5.wav\n",
      "Downloading: freeman_two_cities_0.wav\n",
      "Downloading: freeman_two_cities_1.wav\n",
      "Downloading: freeman_two_cities_2.wav\n",
      "Downloading: vader_hp_0.wav\n",
      "Downloading: vader_hp_1.wav\n",
      "Downloading: vader_hp_2.wav\n",
      "Downloading: vader_hp_3.wav\n",
      "Downloading: vader_hp_4.wav\n",
      "Downloading: vader_hp_5.wav\n",
      "Downloading: vader_two_cities_0.wav\n",
      "Downloading: vader_two_cities_1.wav\n",
      "Downloading: vader_two_cities_2.wav\n"
     ]
    }
   ],
   "source": [
    "# When the job is finished we should have all of the results files in S3. Here, we'll just download them.\n",
    "for f in s3.Bucket(bucket_name).objects.all():\n",
    "    file_name = f.key\n",
    "    if 'vader' in file_name or 'freeman' in file_name:\n",
    "        print(f'Downloading: {file_name}')\n",
    "        s3.Bucket(bucket_name).download_file(file_name, f'./data/{file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythondata",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
